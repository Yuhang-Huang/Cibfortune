#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-VL-8B-Instruct Webç•Œé¢å¯åŠ¨å™¨
æä¾›å¤šç§ç•Œé¢é€‰æ‹©
"""

import os
import sys
import subprocess
import webbrowser
import time

def print_banner():
    """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                Qwen3-VL-8B-Instruct å¤šæ¨¡æ€å¤§æ¨¡å‹Webç•Œé¢         â•‘
â•‘                        å¯åŠ¨å™¨                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    
    missing_deps = []
    
    try:
        import gradio
        print(f"âœ“ Gradio: {gradio.__version__}")
    except ImportError:
        missing_deps.append("gradio>=4.0.0")
        print("âœ— Gradioæœªå®‰è£…")
    
    try:
        import torch
        print(f"âœ“ PyTorch: {torch.__version__}")
    except ImportError:
        missing_deps.append("torch")
        print("âœ— PyTorchæœªå®‰è£…")
    
    try:
        from transformers import Qwen3VLForConditionalGeneration
        print("âœ“ Transformers: æ”¯æŒQwen3VL")
    except ImportError:
        missing_deps.append("transformers")
        print("âœ— Transformersæœªå®‰è£…")
    
    if missing_deps:
        print(f"\nç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    return True

def install_missing_deps():
    """å®‰è£…ç¼ºå¤±çš„ä¾èµ–"""
    print("ğŸ“¦ å®‰è£…ç¼ºå¤±çš„ä¾èµ–...")
    
    deps = ["gradio>=4.0.0", "torch", "transformers", "accelerate", "sentencepiece", "protobuf", "Pillow", "requests"]
    
    for dep in deps:
        try:
            print(f"å®‰è£… {dep}...")
            subprocess.run([sys.executable, "-m", "pip", "install", dep], check=True, capture_output=True)
            print(f"âœ“ {dep} å®‰è£…æˆåŠŸ")
        except subprocess.CalledProcessError as e:
            print(f"âœ— {dep} å®‰è£…å¤±è´¥: {e}")
            return False
    
    return True

def check_model():
    """æ£€æŸ¥æ¨¡å‹"""
    model_path = "/data/storage1/wulin/models/qwen3-vl-8b-instruct"
    
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹è·¯å¾„: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files = ["config.json", "tokenizer_config.json"]
    missing_files = []
    
    for file in required_files:
        if not os.path.exists(os.path.join(model_path, file)):
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ï¼Œç¼ºå°‘: {', '.join(missing_files)}")
        return False
    
    print("âœ… æ¨¡å‹æ£€æŸ¥é€šè¿‡")
    return True

def show_interface_menu():
    """æ˜¾ç¤ºç•Œé¢é€‰æ‹©èœå•"""
    print("\n" + "="*60)
    print("1. æ™ºèƒ½åŠ©æ‰‹ (ç«¯å£7862)")
    print("   - æ¨¡å¼åˆ‡æ¢ï¼šé€šç”¨ç‰ˆ / ä¸“ä¸šç‰ˆ")
    print("   - è§¦å±ä¼˜åŒ–ï¼šæ›´å¤§æŒ‰é’®ä¸é—´è·")
    print("")
    print("2. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€")
    print("3. å®‰è£…ä¾èµ–")
    print("0. é€€å‡º")
    print("="*60)

def check_system_status():
    """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
    print("\nğŸ” ç³»ç»ŸçŠ¶æ€æ£€æŸ¥:")
    print("-" * 40)
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ£€æŸ¥å†…å­˜
    try:
        import psutil
        memory = psutil.virtual_memory()
        total_gb = memory.total / (1024**3)
        available_gb = memory.available / (1024**3)
        print(f"ç³»ç»Ÿå†…å­˜: {total_gb:.1f}GB æ€»è®¡, {available_gb:.1f}GB å¯ç”¨")
    except ImportError:
        print("ç³»ç»Ÿå†…å­˜: æ— æ³•æ£€æµ‹ (psutilæœªå®‰è£…)")
    
    # æ£€æŸ¥CUDA
    try:
        import torch
        if torch.cuda.is_available():
            print(f"CUDA: å¯ç”¨ (è®¾å¤‡æ•°é‡: {torch.cuda.device_count()})")
            for i in range(torch.cuda.device_count()):
                print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        else:
            print("CUDA: ä¸å¯ç”¨")
    except ImportError:
        print("CUDA: æ— æ³•æ£€æµ‹ (PyTorchæœªå®‰è£…)")
    
    # æ£€æŸ¥æ¨¡å‹
    model_ok = check_model()
    
    # æ£€æŸ¥ä¾èµ–
    deps_ok = check_dependencies()
    
    print("\nğŸ“Š çŠ¶æ€æ€»ç»“:")
    print(f"æ¨¡å‹: {'âœ… æ­£å¸¸' if model_ok else 'âŒ å¼‚å¸¸'}")
    print(f"ä¾èµ–: {'âœ… æ­£å¸¸' if deps_ok else 'âŒ å¼‚å¸¸'}")
    
    if model_ok and deps_ok:
        print("ğŸ‰ ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥å¯åŠ¨ç•Œé¢ï¼")
    else:
        print("âš ï¸  ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼Œè¯·å…ˆè§£å†³é—®é¢˜")

def main():
    """ä¸»å‡½æ•°"""
    print_banner()
    
    while True:
        show_interface_menu()
        
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (0-3): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        elif choice == "1":
            if check_dependencies() and check_model():
                try:
                    from gradio_unified import main as unified_main
                    unified_main()
                except Exception as e:
                    print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
            else:
                print("âŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆè§£å†³é—®é¢˜")
        elif choice == "2":
            check_system_status()
        elif choice == "3":
            if install_missing_deps():
                print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
            else:
                print("âŒ ä¾èµ–å®‰è£…å¤±è´¥")
        else:
            print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

if __name__ == "__main__":
    main()
